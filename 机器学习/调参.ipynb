{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search：网格搜索，一种调参手段；穷举搜索：在所有候选的参数选择中，通过循环遍历，尝试每一种可能性，表现最好的参数就是最终的结果。其原理就像是在数组里找最大值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 网格搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.model_selection.GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
    "\n",
    "- estimator: 模型\n",
    "- param_grid: 要循环的参数，字典或含字典的列表\n",
    "- scoring: 评估指标\n",
    "- cv: 交叉验证折数\n",
    "\n",
    "属性：\n",
    "\n",
    "- best_estimator: 最优模型\n",
    "- best_score_: 最高分数\n",
    "- best_params_: 最优参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 未调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9733333333333334"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "iris = load_iris()\n",
    "svc = SVC()\n",
    "svc.fit(iris.data, iris.target)\n",
    "svc.score(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调参后"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9800000000000001\n",
      "SVC(C=1, gamma=0.1)\n",
      "{'C': 1, 'gamma': 0.1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "parameters = {'gamma': [0.001,0.01,0.1,1,10,100],\n",
    "              'C': [0.001,0.01,0.1,1,10,100]}\n",
    "\n",
    "svc = SVC()\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(iris.data, iris.target)\n",
    "\n",
    "# 最高分数\n",
    "print(clf.best_score_)\n",
    "# 最优模型\n",
    "print(clf.best_estimator_)\n",
    "# 最优参数\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 随机搜索\n",
    "\n",
    "[参考](https://www.cnblogs.com/wj-1314/p/10422159.html)\n",
    "\n",
    "我们在搜索超参数的时候，如果超参数个数较少（三四个或者更少），那么我们可以采用网格搜索，一种穷尽式的搜索方法。但是当超参数个数比较多的时候，我们仍然采用网格搜索，那么搜索所需时间将会指数级上升。\n",
    "\n",
    "所以有人就提出了随机搜索的方法，随机在超参数空间中搜索几十几百个点，其中就有可能有比较小的值。这种做法比上面稀疏化网格的做法快，而且实验证明，随机搜索法结果比稀疏网格法稍好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.model_selection.RandomizedSearchCV(estimator, param_distributions, *, n_iter=10, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', random_state=None, error_score=nan, return_train_score=False)\n",
    "\n",
    "- estimator: 模型\n",
    "- param_distributions: 要循环的参数，字典或含字典的列表\n",
    "- n_iter: 迭代次数\n",
    "- scoring: 评估指标\n",
    "- cv: 交叉验证折数\n",
    "- random_state: 随机数\n",
    "\n",
    "属性：\n",
    "\n",
    "- best_estimator: 最优模型\n",
    "- best_score_: 最高分数\n",
    "- best_params_: 最优参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666668\n",
      "{'gamma': 4.1000000000000005, 'C': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "parameters = {'gamma': np.arange(0, 100, 0.1),\n",
    "              'C': [0.001,0.01,0.1,1,10,100]}\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "clf = RandomizedSearchCV(svc, parameters, n_iter=300)\n",
    "\n",
    "clf.fit(iris.data, iris.target)\n",
    "\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 贝叶斯优化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考资料：\n",
    "\n",
    "[贝叶斯优化的Bayes优化参数调整原理与实践](https://www.pythonf.cn/read/136216)\n",
    "\n",
    "[调参神器贝叶斯优化（bayesian-optimization）实战篇](https://www.jianshu.com/p/92d8943fb0ba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先看看不调参之前的结果\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "x, y = make_classification(n_samples=1000,n_features=10,n_classes=2)\n",
    "gbdt = GradientBoostingClassifier()\n",
    "cross_val_score(gbdt, x, y, cv=5, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bayes调参初探\n",
    "\n",
    "我们先定义一个目标函数，里面放入我们希望优化的函数。比如此时，函数输入为GradientBoostingClassifier的参数，输出为模型交叉验证5次的AUC均值，作为我们的目标函数。因为bayes_opt库只支持最大值，所以最后的输出如果是越小越好，那么需要在前面加上负号，以转为最大值。由于bayes优化只能优化连续超参数，因此要加上int()转为离散超参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BayesianOptimization().maximize(init_points=5, n_iter=25)\n",
    "\n",
    "init_points,执行随机搜索的步数;n_iter,执行贝叶斯优化的步数\n",
    "\n",
    "默认：init_points=5, n_iter=25\n",
    "\n",
    "迭代次数由两部分组成，随机搜索的步数和贝叶斯优化的步数，贝叶斯优化的步数要多一点，步骤越多，就越有可能找到一个好的最大值。随机探索可以通过扩大探索空间而有所帮助。这里以迭代30次为例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | max_fe... | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.9684  \u001b[0m | \u001b[0m 11.66   \u001b[0m | \u001b[0m 0.1046  \u001b[0m | \u001b[0m 7.42    \u001b[0m | \u001b[0m 181.8   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.9697  \u001b[0m | \u001b[95m 6.005   \u001b[0m | \u001b[95m 0.911   \u001b[0m | \u001b[95m 11.27   \u001b[0m | \u001b[95m 75.46   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.9685  \u001b[0m | \u001b[0m 10.58   \u001b[0m | \u001b[0m 0.5531  \u001b[0m | \u001b[0m 4.687   \u001b[0m | \u001b[0m 193.1   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.9676  \u001b[0m | \u001b[0m 9.528   \u001b[0m | \u001b[0m 0.9797  \u001b[0m | \u001b[0m 10.95   \u001b[0m | \u001b[0m 100.9   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.9693  \u001b[0m | \u001b[0m 13.01   \u001b[0m | \u001b[0m 0.3497  \u001b[0m | \u001b[0m 9.929   \u001b[0m | \u001b[0m 146.8   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.9671  \u001b[0m | \u001b[0m 6.117   \u001b[0m | \u001b[0m 0.1382  \u001b[0m | \u001b[0m 10.64   \u001b[0m | \u001b[0m 75.7    \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.9689  \u001b[0m | \u001b[0m 10.49   \u001b[0m | \u001b[0m 0.9917  \u001b[0m | \u001b[0m 6.654   \u001b[0m | \u001b[0m 216.8   \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m 0.9711  \u001b[0m | \u001b[95m 8.685   \u001b[0m | \u001b[95m 0.5938  \u001b[0m | \u001b[95m 24.69   \u001b[0m | \u001b[95m 106.5   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.9708  \u001b[0m | \u001b[0m 6.369   \u001b[0m | \u001b[0m 0.5485  \u001b[0m | \u001b[0m 10.02   \u001b[0m | \u001b[0m 57.18   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.9675  \u001b[0m | \u001b[0m 8.441   \u001b[0m | \u001b[0m 0.9778  \u001b[0m | \u001b[0m 10.76   \u001b[0m | \u001b[0m 36.36   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.9683  \u001b[0m | \u001b[0m 6.996   \u001b[0m | \u001b[0m 0.1021  \u001b[0m | \u001b[0m 13.38   \u001b[0m | \u001b[0m 164.4   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.9695  \u001b[0m | \u001b[0m 14.1    \u001b[0m | \u001b[0m 0.168   \u001b[0m | \u001b[0m 20.69   \u001b[0m | \u001b[0m 136.3   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.9693  \u001b[0m | \u001b[0m 9.884   \u001b[0m | \u001b[0m 0.4157  \u001b[0m | \u001b[0m 5.576   \u001b[0m | \u001b[0m 96.05   \u001b[0m |\n",
      "| \u001b[95m 14      \u001b[0m | \u001b[95m 0.9715  \u001b[0m | \u001b[95m 11.38   \u001b[0m | \u001b[95m 0.3444  \u001b[0m | \u001b[95m 20.38   \u001b[0m | \u001b[95m 14.54   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.9689  \u001b[0m | \u001b[0m 14.08   \u001b[0m | \u001b[0m 0.8587  \u001b[0m | \u001b[0m 24.35   \u001b[0m | \u001b[0m 60.62   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.9658  \u001b[0m | \u001b[0m 6.916   \u001b[0m | \u001b[0m 0.1106  \u001b[0m | \u001b[0m 3.266   \u001b[0m | \u001b[0m 46.51   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.9675  \u001b[0m | \u001b[0m 14.78   \u001b[0m | \u001b[0m 0.3827  \u001b[0m | \u001b[0m 11.21   \u001b[0m | \u001b[0m 73.15   \u001b[0m |\n",
      "| \u001b[95m 18      \u001b[0m | \u001b[95m 0.9724  \u001b[0m | \u001b[95m 5.779   \u001b[0m | \u001b[95m 0.49    \u001b[0m | \u001b[95m 8.589   \u001b[0m | \u001b[95m 43.32   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.9686  \u001b[0m | \u001b[0m 12.6    \u001b[0m | \u001b[0m 0.3914  \u001b[0m | \u001b[0m 23.97   \u001b[0m | \u001b[0m 27.55   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.97    \u001b[0m | \u001b[0m 6.362   \u001b[0m | \u001b[0m 0.512   \u001b[0m | \u001b[0m 15.73   \u001b[0m | \u001b[0m 63.25   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.9702  \u001b[0m | \u001b[0m 8.91    \u001b[0m | \u001b[0m 0.4049  \u001b[0m | \u001b[0m 11.13   \u001b[0m | \u001b[0m 156.3   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.9689  \u001b[0m | \u001b[0m 11.26   \u001b[0m | \u001b[0m 0.8174  \u001b[0m | \u001b[0m 6.109   \u001b[0m | \u001b[0m 159.0   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.9689  \u001b[0m | \u001b[0m 13.93   \u001b[0m | \u001b[0m 0.6471  \u001b[0m | \u001b[0m 7.673   \u001b[0m | \u001b[0m 71.29   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.968   \u001b[0m | \u001b[0m 12.42   \u001b[0m | \u001b[0m 0.2431  \u001b[0m | \u001b[0m 17.75   \u001b[0m | \u001b[0m 215.4   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.9676  \u001b[0m | \u001b[0m 10.25   \u001b[0m | \u001b[0m 0.5043  \u001b[0m | \u001b[0m 24.54   \u001b[0m | \u001b[0m 160.5   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.9684  \u001b[0m | \u001b[0m 5.234   \u001b[0m | \u001b[0m 0.243   \u001b[0m | \u001b[0m 8.875   \u001b[0m | \u001b[0m 43.41   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.9704  \u001b[0m | \u001b[0m 10.49   \u001b[0m | \u001b[0m 0.7048  \u001b[0m | \u001b[0m 24.53   \u001b[0m | \u001b[0m 21.05   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.9703  \u001b[0m | \u001b[0m 7.431   \u001b[0m | \u001b[0m 0.7711  \u001b[0m | \u001b[0m 14.47   \u001b[0m | \u001b[0m 105.2   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.9629  \u001b[0m | \u001b[0m 12.44   \u001b[0m | \u001b[0m 0.1453  \u001b[0m | \u001b[0m 5.85    \u001b[0m | \u001b[0m 58.23   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.9672  \u001b[0m | \u001b[0m 6.08    \u001b[0m | \u001b[0m 0.9712  \u001b[0m | \u001b[0m 8.179   \u001b[0m | \u001b[0m 170.2   \u001b[0m |\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "def gbdt_cv(n_estimators, min_samples_split, max_features, max_depth):\n",
    "    res = cross_val_score( \n",
    "        GradientBoostingClassifier(n_estimators=int(n_estimators),\n",
    "                                min_samples_split=int(min_samples_split),\n",
    "                                max_features=min(max_features, 0.999), # float\n",
    "                                max_depth=int(max_depth),\n",
    "                                random_state=2\n",
    "        ),\n",
    "        x, y, scoring='roc_auc', cv=5\n",
    "    ).mean()\n",
    "    return res\n",
    "\n",
    "\n",
    "# 然后我们就可以实例化一个bayes优化对象了\n",
    "# 里面的第一个参数是我们的优化目标函数，第二个参数是我们所需要输入的超参数名称，以及其范围。超参数名称必须和目标函数的输入名称一一对应。\n",
    "gbdt_op = BayesianOptimization(\n",
    "        gbdt_cv,\n",
    "        {'n_estimators': (10, 250),\n",
    "        'min_samples_split': (2, 25),\n",
    "        'max_features': (0.1, 0.999),\n",
    "        'max_depth': (5, 15)}\n",
    "    )\n",
    "# 运行bayes优化\n",
    "gbdt_op.maximize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': 0.9723799999999999, 'params': {'max_depth': 5.778950785247591, 'max_features': 0.4899642525170448, 'min_samples_split': 8.58901183740917, 'n_estimators': 43.31502231986158}}\n"
     ]
    }
   ],
   "source": [
    "# 查看当前最优的参数和结果\n",
    "print(gbdt_op.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97227\n",
      "0.97156\n"
     ]
    }
   ],
   "source": [
    "# 用最优的参数组合定义一个新的GBDT，在和之前同样的数据上做训练，并生成评估得分。\n",
    "gbdt1 = GradientBoostingClassifier(n_estimators=43,\n",
    "                                   max_depth=5,\n",
    "                                   min_samples_split=9,\n",
    "                                   max_features=0.49,\n",
    "                                   random_state=2)\n",
    "# 调参后\n",
    "print(cross_val_score(gbdt1, x, y, cv=5, scoring='roc_auc').mean())\n",
    "# 调参前\n",
    "print(cross_val_score(gbdt, x, y, cv=5, scoring='roc_auc').mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
