## 查看数据

df.info()

- 样本大小
- 特征变量数据类型
- 是否有缺失值

df.describe() 查看统计信息

- 样本数
- 均值
- 标准差
- 最小值
- 最大值

df.head() 查看字段信息

## 可视化数据分布

### 箱型图

查看是否有偏离值，偏离较大的异常值，可以考虑删除

### 直方图和Q-Q图

Q-Q图是指数据的分位数和正态分布的分位数对比参照的图，如果数据符合正态分布，则所有的点都会落在直线上。如果不符合正态分布，可以使用数据变换对其进行处理。

### KDE分布图

KDE（Kernel Density Estimation，核密度估计）可以理解为是直方图的加窗平滑。通过绘制KDE分布图，可以查看并对比训练集和测试集中特征变量的分布情况，发现两个数据集中分布不一致的特征变量。

分布不一致，会导致模型的泛化能力变差，需要删除此类特征。

### 线性回归关系图

主要用于分析变量之间的线性回归关系。

查看特征和target的线性关系。

## 查看特征变量的相关性

### 计算相关性系数

df.corr()

### 相关性热力图

sns.heatmap()

### 根据相关系数筛选特征变量

相关系数越大，就认为对target变量的线性影响越大。

> 相关性选择主要用于判别线性相关，对于target变量如果存在更复杂的函数形式的影响，则建议使用树模型的特征重要性去选择。

- 寻找K个与target变量最相关的特征变量
- 与target变量的相关系数>0.5的特征变量

### Box-Cox变换

由于线性回归是基于正态分布的，因此在进行统计分析时，需要将数据转换使其符合正态分布。

Box-Cox变换是统计建模中常用的一种数据转换方法。在连续的响应变量不满足正态分布时，可以使用Box-Cox变换，这一变换可以使线性回归模型在满足线性、正态性、独立性及方差齐性的同时，又不丢失信息。在对数据做Box-Cox变换之后，可以在一定程度上减小不可观测的误差和预测变量的相关性，这有利于线性模型的拟合及分析出特征的相关性。

在做Box-Cox变换之前，需要对数据做归一化预处理。在归一化时，对数据进行合并操作可以使训练数据和测试数据一致。这种方式可以在线下分析建模中使用，而线上部署只需采用训练数据的归一化即可。

也可以分开对训练数据和测试数据进行归一化处理，不过这种方式需要建立在训练数据和测试数据分布一致的前提下，建议在数据量大的情况下使用(数据量大，一般分布比较一致)，能加快归一化的速度。而数据量较小会存在分布差异较大的情况，此时，在数据分析和线下建模中应该将数据统一归一化。